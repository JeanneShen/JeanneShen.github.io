<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/stich-32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/picaso-16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="TD7比较不同内存的矩阵加法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979">
<meta property="og:type" content="article">
<meta property="og:title" content="Day Day Up">
<meta property="og:url" content="http://example.com/2023/02/19/GPU/2023-02-19-%E4%BB%A3%E7%A0%812/index.html">
<meta property="og:site_name" content="Day Day Up">
<meta property="og:description" content="TD7比较不同内存的矩阵加法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-02-19T22:42:43.150Z">
<meta property="article:modified_time" content="2023-02-19T22:55:20.550Z">
<meta property="article:author" content="安然">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2023/02/19/GPU/2023-02-19-%E4%BB%A3%E7%A0%812/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title> | Day Day Up</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Day Day Up</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="calendar fa-fw"></i>日程表</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/02/19/GPU/2023-02-19-%E4%BB%A3%E7%A0%812/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="安然">
      <meta itemprop="description" content="随手写点什么">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Day Day Up">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-19 23:42:43 / 修改时间：23:55:20" itemprop="dateCreated datePublished" datetime="2023-02-19T23:42:43+01:00">2023-02-19</time>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="TD7"><a href="#TD7" class="headerlink" title="TD7"></a>TD7</h2><h3 id="比较不同内存的矩阵加法"><a href="#比较不同内存的矩阵加法" class="headerlink" title="比较不同内存的矩阵加法"></a>比较不同内存的矩阵加法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;assert.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">initMatrix</span><span class="params">(<span class="type">float</span> *m, <span class="type">int</span> numRows, <span class="type">int</span> numCols)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">computeMatrixMulCPU</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">int</span> numARows, <span class="type">int</span> numAColumns, <span class="type">int</span> numBRows, <span class="type">int</span> numBColumns)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">compareMatrix</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">int</span> numRows, <span class="type">int</span> numColumns)</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CREATE_CUDAEVENT cudaEvent_t start, stop; \</span></span><br><span class="line"><span class="meta">cudaEventCreate(&amp;start); \</span></span><br><span class="line"><span class="meta">cudaEventCreate(&amp;stop);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> START_CUDAEVENT cudaEventRecord(start, 0);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> STOP_AND_PRINT_CUDAEVENT(txt) cudaEventRecord(stop, 0);\</span></span><br><span class="line"><span class="meta">cudaEventSynchronize(stop);\</span></span><br><span class="line"><span class="meta">&#123;float elapsedTime;\</span></span><br><span class="line"><span class="meta">cudaEventElapsedTime(&amp;elapsedTime, start, stop);\</span></span><br><span class="line"><span class="meta">printf(<span class="string">&quot;Time to %s %3.1f ms\n&quot;</span>, #txt, elapsedTime);&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TILE_WIDTH 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//ComputeC=A*B</span></span><br><span class="line">__global__</span><br><span class="line"><span class="type">void</span> <span class="title function_">sgemm</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">int</span> numARows, <span class="type">int</span> numAColumns, <span class="type">int</span> numBRows, <span class="type">int</span> numBColumns)</span> &#123;</span><br><span class="line">   __shared__ <span class="type">float</span> ds_M[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">   __shared__ <span class="type">float</span> ds_N[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">   <span class="type">int</span> bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y,</span><br><span class="line">   row = by * TILE_WIDTH + ty, col = bx * TILE_WIDTH + tx;</span><br><span class="line">   <span class="type">float</span> Pvalue = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> m = <span class="number">0</span>; m &lt; (numAColumns - <span class="number">1</span>) / TILE_WIDTH + <span class="number">1</span>; ++m) &#123;</span><br><span class="line">       <span class="keyword">if</span> (row &lt; numARows &amp;&amp; m * TILE_WIDTH + tx &lt; numAColumns)</span><br><span class="line">           ds_M[ty][tx] = A[row * numAColumns + m * TILE_WIDTH + tx];</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           ds_M[ty][tx] = <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">if</span> (col &lt; numBColumns &amp;&amp; m * TILE_WIDTH + ty &lt; numBRows)</span><br><span class="line">           ds_N[ty][tx] = B[(m * TILE_WIDTH + ty) * numBColumns + col];</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           ds_N[ty][tx] = <span class="number">0</span>;</span><br><span class="line">       __syncthreads();</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; TILE_WIDTH; ++k)</span><br><span class="line">           Pvalue += ds_M[ty][k] * ds_N[k][tx];</span><br><span class="line">       __syncthreads();</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (row &lt; numARows &amp;&amp; col &lt; numBColumns)</span><br><span class="line">       C[row * numBColumns + col] = Pvalue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">   CREATE_CUDAEVENT</span><br><span class="line"></span><br><span class="line">   <span class="type">int</span> numARows = atoi(argv[<span class="number">1</span>]); <span class="comment">// number of rows in the matrix A</span></span><br><span class="line">   <span class="type">int</span> numAColumns = atoi(argv[<span class="number">2</span>]); <span class="comment">// number of columns in the matrix A</span></span><br><span class="line">   <span class="type">int</span> numBRows = atoi(argv[<span class="number">3</span>]); <span class="comment">// number of rows in the matrix B</span></span><br><span class="line">   <span class="type">int</span> numBColumns = atoi(argv[<span class="number">4</span>]); <span class="comment">// number of columns in the matrix B</span></span><br><span class="line">   <span class="type">int</span> numCRows = numARows; <span class="comment">// number of rows in the matrix C</span></span><br><span class="line">   <span class="type">int</span> numCColumns = numBColumns; <span class="comment">// number of columns in the matrix C</span></span><br><span class="line">   assert(numAColumns == numBRows);</span><br><span class="line"></span><br><span class="line">   <span class="type">float</span> *A = (<span class="type">float</span> *)<span class="built_in">malloc</span>(numARows*numAColumns*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">   <span class="type">float</span> *B = (<span class="type">float</span> *)<span class="built_in">malloc</span>(numBRows*numBColumns*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">   <span class="type">float</span> *C = (<span class="type">float</span> *)<span class="built_in">malloc</span>(numCRows*numCColumns*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">   <span class="type">float</span> *hostC = (<span class="type">float</span> *)<span class="built_in">malloc</span>(numCRows*numCColumns*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Initialize matrices on the host</span></span><br><span class="line">   initMatrix(A, numARows, numAColumns);</span><br><span class="line">   initMatrix(B, numBRows, numBColumns);</span><br><span class="line"></span><br><span class="line">   START_CUDAEVENT</span><br><span class="line">   <span class="title function_">computeMatrixMulCPU</span><span class="params">(A, B, C, numARows, numAColumns, numBRows, numBColumns)</span>;</span><br><span class="line">   STOP_AND_PRINT_CUDAEVENT(compute CPU)</span><br><span class="line"></span><br><span class="line">   <span class="comment">// CUDA PART</span></span><br><span class="line">   <span class="type">float</span> *deviceA;</span><br><span class="line">   <span class="type">float</span> *deviceB;</span><br><span class="line">   <span class="type">float</span> *deviceC;</span><br><span class="line">   cudaMalloc((<span class="type">void</span> **)&amp;deviceA, numARows * numAColumns * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">   cudaMalloc((<span class="type">void</span> **)&amp;deviceB, numBRows * numBColumns * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">   cudaMalloc((<span class="type">void</span> **)&amp;deviceC, numCRows * numBColumns * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">   cudaMemcpy(deviceA, A, numARows * numAColumns * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice);</span><br><span class="line">   cudaMemcpy(deviceB, B, numBRows * numBColumns * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">   cudaMemset(deviceC, <span class="number">0</span>, numCRows * numCColumns * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">   dim3 <span class="title function_">blockDim</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span>;</span><br><span class="line">   dim3 <span class="title function_">gridDim</span><span class="params">(<span class="built_in">ceil</span>(((<span class="type">float</span>)numBColumns) / blockDim.x), <span class="built_in">ceil</span>(((<span class="type">float</span>)numARows) / blockDim.y))</span>;</span><br><span class="line">   START_CUDAEVENT</span><br><span class="line">   sgemm&lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;(deviceA, deviceB, deviceC, numARows, numAColumns, numBRows, numBColumns);</span><br><span class="line">   STOP_AND_PRINT_CUDAEVENT(compute GPU)</span><br><span class="line"></span><br><span class="line">   cudaMemcpy(hostC, deviceC, numARows * numBColumns * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">   <span class="comment">// END CUDA PART</span></span><br><span class="line"></span><br><span class="line">   compareMatrix(C, hostC, numCRows, numCColumns);</span><br><span class="line"></span><br><span class="line">   cudaFree(deviceA);</span><br><span class="line">   cudaFree(deviceB);</span><br><span class="line">   cudaFree(deviceC);</span><br><span class="line"></span><br><span class="line">   <span class="built_in">free</span>(A);</span><br><span class="line">   <span class="built_in">free</span>(B);</span><br><span class="line">   <span class="built_in">free</span>(C);</span><br><span class="line"></span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">initMatrix</span><span class="params">(<span class="type">float</span> *m, <span class="type">int</span> numRows, <span class="type">int</span> numCols)</span>&#123;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;numRows; i++)&#123;</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> j=<span class="number">0</span>; j&lt;numCols; j++)&#123;</span><br><span class="line">           m[i*numCols+j] = <span class="built_in">sin</span>(i*numCols+j);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">computeMatrixMulCPU</span><span class="params">(</span></span><br><span class="line"><span class="params">   <span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C,</span></span><br><span class="line"><span class="params">   <span class="type">int</span> numARows, <span class="type">int</span> numAColumns,</span></span><br><span class="line"><span class="params">   <span class="type">int</span> numBRows, <span class="type">int</span> numBColumns</span></span><br><span class="line"><span class="params">)</span>&#123;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> row = <span class="number">0</span>; row &lt; numARows; row++)&#123;</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> col = <span class="number">0</span>; col &lt; numBColumns; col++)&#123;   </span><br><span class="line">           C[row * numBColumns + col] = <span class="number">0.0</span>;         </span><br><span class="line">           <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; numAColumns; n++)&#123;</span><br><span class="line">               C[row * numBColumns + col] += A[row * numAColumns + n] * B[n * numBColumns + col];</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">compareMatrix</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">int</span> numRows, <span class="type">int</span> numColumns)</span>&#123;</span><br><span class="line">   <span class="type">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">   <span class="type">float</span> max = <span class="number">0.0</span>;</span><br><span class="line">   <span class="type">float</span> min = <span class="number">10.0</span>;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> row = <span class="number">0</span>; row &lt; numRows; row++)&#123;</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> col = <span class="number">0</span>; col &lt; numColumns; col++)&#123;    </span><br><span class="line">           <span class="type">float</span> diff = A[row*numColumns+col] - B[row*numColumns+col];</span><br><span class="line">           <span class="keyword">if</span> (diff &gt; max) max = diff;</span><br><span class="line">           <span class="keyword">if</span> (diff &lt; min) min = diff;</span><br><span class="line">           sum += diff;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;mean: &quot;</span> &lt;&lt; sum / (numRows*numColumns) &lt;&lt; <span class="string">&quot; max: &quot;</span> &lt;&lt; max &lt;&lt; <span class="string">&quot; min: &quot;</span> &lt;&lt; min &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">./addvec_answer3</span><br><span class="line">&gt;&gt;&gt; Results <span class="keyword">for</span> MemCopy</span><br><span class="line">Time to [Classical] host allocation 0.1 ms</span><br><span class="line">Time to [Classical] Initialize 117.5 ms</span><br><span class="line">Time to [Classical] device allocation 29.5 ms</span><br><span class="line">Time to [Classical] MemCopy Host to Device 64.8 ms</span><br><span class="line">Time to [Classical] execution 14.8 ms</span><br><span class="line">Time to [Classical] MemCopy Device to Host 26.2 ms</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Results <span class="keyword">for</span> Pinned Memory</span><br><span class="line">Time to [Pinned] host allocation 32.5 ms</span><br><span class="line">Time to [Pinned] initialize 1083.4 ms</span><br><span class="line">Time to [Pinned] device allocation 35.6 ms</span><br><span class="line">Time to [Pinned] MemCopy Host to Device 34.3 ms</span><br><span class="line">Time to [Pinned] execution 4.8 ms</span><br><span class="line">Time to [Pinned] MemCopy Device to Host 3.3 ms</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Results <span class="keyword">for</span> Unified Memory</span><br><span class="line">Time to [Unified Memory] memory allocation 33.8 ms</span><br><span class="line">Time to [Unified Memory] initialize 115.5 ms</span><br><span class="line">Time to [Unified Memory] MemCopy Host to Device 0.0 ms</span><br><span class="line">Time to [Unified Memory] execution 11.3 ms</span><br><span class="line">Time to [Unified Memory] MemCopy Device to Host 0.0 ms</span><br></pre></td></tr></table></figure>
<h2 id="TD8-直方图统计"><a href="#TD8-直方图统计" class="headerlink" title="TD8 直方图统计"></a>TD8 直方图统计</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;text.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NB_ASCII_CHAR 128</span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> BlockNumber = <span class="number">16</span>;</span><br><span class="line"></span><br><span class="line">__global__</span><br><span class="line"><span class="type">void</span> <span class="title function_">histo_kernel</span><span class="params">( <span class="type">char</span> *buffer , <span class="type">long</span> size , <span class="type">int</span> *histo )</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> i = threadIdx . x + blockIdx . x * blockDim . x ;</span><br><span class="line"><span class="comment">// stride is total number of threads</span></span><br><span class="line"><span class="type">int</span> stride = blockDim . x * gridDim . x ;</span><br><span class="line"><span class="comment">// All threads handle blockDim . x * gridDim . x</span></span><br><span class="line"><span class="comment">// consecutive elements</span></span><br><span class="line"><span class="keyword">while</span> ( i &lt; size ) &#123;</span><br><span class="line">        atomicAdd (&amp;(histo[buffer[i]]) , <span class="number">1</span>) ;</span><br><span class="line">        i += stride ;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__global__</span><br><span class="line"><span class="type">void</span> <span class="title function_">histo_kernel_shared</span><span class="params">( <span class="type">char</span> *buffer , <span class="type">long</span> size , <span class="type">int</span> *histo)</span>&#123;</span><br><span class="line">__shared__  <span class="type">unsigned</span> <span class="type">int</span> histo_private[NB_ASCII_CHAR];</span><br><span class="line"><span class="keyword">if</span> ( threadIdx.x &lt; NB_ASCII_CHAR) histo_private[threadIdx.x] = <span class="number">0</span>;</span><br><span class="line">__syncthreads () ;</span><br><span class="line"><span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x ;</span><br><span class="line"><span class="comment">// stride is total number of threads</span></span><br><span class="line"><span class="type">int</span> stride = blockDim.x * gridDim.x ;</span><br><span class="line"><span class="keyword">while</span> ( i &lt; size ) &#123;</span><br><span class="line">    atomicAdd ( &amp;( histo_private[buffer[i]]) , <span class="number">1</span>) ;</span><br><span class="line">    i += stride ;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// wait for all other threads in the block to finish</span></span><br><span class="line">__syncthreads () ;</span><br><span class="line"><span class="keyword">if</span> ( threadIdx.x &lt; NB_ASCII_CHAR) &#123;</span><br><span class="line">atomicAdd (&amp;( histo [ threadIdx.x ]) , histo_private[ threadIdx.x] ) ;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">( <span class="type">void</span> )</span> &#123;</span><br><span class="line">    <span class="type">int</span> len = <span class="built_in">strlen</span>(h_str);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;len:%d\n&quot;</span>, len);</span><br><span class="line">    <span class="type">int</span> size = len*<span class="keyword">sizeof</span>(<span class="type">char</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">char</span> *d_str;</span><br><span class="line">    <span class="type">int</span> *h_histo, *d_histo;</span><br><span class="line"></span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    cudaEventCreate( &amp;start );</span><br><span class="line">    cudaEventCreate( &amp;stop );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// GPU computation</span></span><br><span class="line">    h_histo = (<span class="type">int</span>*)<span class="built_in">malloc</span>( len*<span class="keyword">sizeof</span>(<span class="type">int</span>) );</span><br><span class="line"></span><br><span class="line">    cudaMalloc( (<span class="type">void</span>**)&amp;d_str, len*<span class="keyword">sizeof</span>(<span class="type">char</span>) );</span><br><span class="line">    cudaMalloc( (<span class="type">void</span>**)&amp;d_histo, len*<span class="keyword">sizeof</span>(<span class="type">int</span>) );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cudaEventRecord( start, <span class="number">0</span> );</span><br><span class="line">    cudaMemcpy( d_str, h_str, len*<span class="keyword">sizeof</span>(<span class="type">char</span>), cudaMemcpyHostToDevice );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    histo_kernel_shared&lt;&lt;&lt;BlockNumber,threadsPerBlock&gt;&gt;&gt;( d_str, size, d_histo );</span><br><span class="line"></span><br><span class="line">    cudaMemcpy( h_histo, d_histo, NB_ASCII_CHAR*<span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost );</span><br><span class="line"></span><br><span class="line">    cudaEventRecord( stop, <span class="number">0</span> );</span><br><span class="line">    cudaEventSynchronize( stop );</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    cudaEventElapsedTime( &amp;elapsedTime, start, stop );</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Total time for  GPU computation with shared memory was %f ms\n&quot;</span>, elapsedTime );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// for (int bean = 0; bean &lt; NB_ASCII_CHAR; bean++) &#123;</span></span><br><span class="line">    <span class="comment">//     std::cout &lt;&lt; (char) bean &lt;&lt; &quot; : &quot; &lt;&lt; h_histo[bean] &lt;&lt; std::endl;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line">    cudaFree(d_histo);</span><br><span class="line">    cudaFree(d_str);</span><br><span class="line">    <span class="built_in">free</span>(h_histo);</span><br><span class="line"></span><br><span class="line"><span class="comment">// GPU computation with shared memory</span></span><br><span class="line"></span><br><span class="line">    h_histo = (<span class="type">int</span>*)<span class="built_in">malloc</span>( len*<span class="keyword">sizeof</span>(<span class="type">int</span>) );</span><br><span class="line"></span><br><span class="line">    cudaMalloc( (<span class="type">void</span>**)&amp;d_str, len*<span class="keyword">sizeof</span>(<span class="type">char</span>) );</span><br><span class="line">    cudaMalloc( (<span class="type">void</span>**)&amp;d_histo, len*<span class="keyword">sizeof</span>(<span class="type">int</span>) );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cudaEventRecord( start, <span class="number">0</span> );</span><br><span class="line">    cudaMemcpy( d_str, h_str, len*<span class="keyword">sizeof</span>(<span class="type">char</span>), cudaMemcpyHostToDevice );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    histo_kernel&lt;&lt;&lt;BlockNumber,threadsPerBlock&gt;&gt;&gt;( d_str, size, d_histo );</span><br><span class="line"></span><br><span class="line">    cudaMemcpy( h_histo, d_histo, NB_ASCII_CHAR*<span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost );</span><br><span class="line"></span><br><span class="line">    cudaEventRecord( stop, <span class="number">0</span> );</span><br><span class="line">    cudaEventSynchronize( stop );</span><br><span class="line">    cudaEventElapsedTime( &amp;elapsedTime, start, stop );</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Total time for naive GPU computation was %f ms\n&quot;</span>, elapsedTime );</span><br><span class="line">    <span class="comment">// for (int bean = 0; bean &lt; NB_ASCII_CHAR; bean++) &#123;</span></span><br><span class="line">    <span class="comment">//     std::cout &lt;&lt; (char) bean &lt;&lt; &quot; : &quot; &lt;&lt; h_histo[bean] &lt;&lt; std::endl;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">    cudaFree(d_histo);</span><br><span class="line">    cudaFree(d_str);</span><br><span class="line">    <span class="built_in">free</span>(h_histo);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// CPU computation</span></span><br><span class="line"></span><br><span class="line">    cudaEventRecord( start, <span class="number">0</span> );</span><br><span class="line"></span><br><span class="line">    u_int histo[NB_ASCII_CHAR] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; len; i++)&#123;</span><br><span class="line">            histo[h_str[i]]++;</span><br><span class="line">    &#125;    </span><br><span class="line">    <span class="comment">// for (int bean = 0; bean &lt; NB_ASCII_CHAR; bean++) &#123;</span></span><br><span class="line">    <span class="comment">//     std::cout &lt;&lt; (char) bean &lt;&lt; &quot; : &quot; &lt;&lt; histo[bean] &lt;&lt; std::endl;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">    cudaEventRecord( stop, <span class="number">0</span> );</span><br><span class="line">    cudaEventSynchronize( stop );</span><br><span class="line">    cudaEventElapsedTime( &amp;elapsedTime, start, stop );</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Total time for CPU computation was %f ms\n&quot;</span>, elapsedTime );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ./hist_gpu</span><br><span class="line">len:179709</span><br><span class="line">Total time <span class="keyword">for</span>  GPU computation with shared memory was 1.082448 ms</span><br><span class="line">Total time <span class="keyword">for</span> naive GPU computation was 2.703802 ms</span><br><span class="line">Total time <span class="keyword">for</span> CPU computation was 5.037396 ms</span><br></pre></td></tr></table></figure>
<h2 id="TD9"><a href="#TD9" class="headerlink" title="TD9"></a>TD9</h2><h3 id="Pinned内存计算向量加法"><a href="#Pinned内存计算向量加法" class="headerlink" title="Pinned内存计算向量加法"></a>Pinned内存计算向量加法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">__global__</span><br><span class="line"><span class="type">void</span> <span class="title function_">vector_add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c, <span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">/* insert code to calculate the index properly using blockIdx.x, blockDim.x, threadIdx.x */</span></span><br><span class="line">        <span class="type">int</span> index = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; n) c[index] = a[index] + b[index];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* experiment with N */</span></span><br><span class="line"><span class="comment">/* how large can it be? */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N (2048*2048*10)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> THREADS_PER_BLOCK 512</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="comment">/* declare and create CUDA events */</span></span><br><span class="line">        cudaEvent_t start, stop, mem_start, mem_stop;</span><br><span class="line">        cudaEventCreate(&amp;start);</span><br><span class="line">        cudaEventCreate(&amp;stop);</span><br><span class="line">        cudaEventCreate(&amp;mem_start);</span><br><span class="line">        cudaEventCreate(&amp;mem_stop);</span><br><span class="line"></span><br><span class="line">          <span class="type">int</span> *a, *b, *c;</span><br><span class="line">        <span class="type">int</span> *d_a, *d_b, *d_c;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> size = N * <span class="keyword">sizeof</span>( <span class="type">int</span> );</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* allocate space for device copies of a, b, c */</span></span><br><span class="line">        cudaMalloc( &amp;d_a, size );</span><br><span class="line">        cudaMalloc( &amp;d_b, size );</span><br><span class="line">        cudaMalloc( &amp;d_c, size );</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* allocate space for host copies of a, b, c and setup input values */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//a = (int *)malloc( size );</span></span><br><span class="line">        cudaHostAlloc(&amp;a,size,cudaHostAllocDefault);</span><br><span class="line">        <span class="comment">//b = (int *)malloc( size );</span></span><br><span class="line">        cudaHostAlloc(&amp;b,size,cudaHostAllocDefault);</span><br><span class="line">        <span class="comment">//c = (int *)malloc( size );</span></span><br><span class="line">        cudaHostAlloc(&amp;c,size,cudaHostAllocDefault);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>( <span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++ )</span><br><span class="line">        &#123;</span><br><span class="line">                a[i] = b[i] = i;</span><br><span class="line">                c[i] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        cudaEventRecord(mem_start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* copy inputs to device */</span></span><br><span class="line">        <span class="comment">/* fix the parameters needed to copy data to the device */</span></span><br><span class="line">        cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);</span><br><span class="line">        cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> blocks = <span class="built_in">ceil</span>(N / ((<span class="type">float</span>) THREADS_PER_BLOCK));</span><br><span class="line"></span><br><span class="line">        cudaEventRecord(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* launch the kernel on the GPU */</span></span><br><span class="line">        <span class="comment">/* insert the launch parameters to launch the kernel properly using blocks and threads */</span></span><br><span class="line"></span><br><span class="line">        vector_add&lt;&lt;&lt;blocks, THREADS_PER_BLOCK&gt;&gt;&gt;( d_a, d_b, d_c, N );</span><br><span class="line"></span><br><span class="line">        cudaEventRecord(stop, <span class="number">0</span>);</span><br><span class="line">        cudaEventSynchronize(stop);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* copy result back to host */</span></span><br><span class="line">        <span class="comment">/* fix the parameters needed to copy data back to the host */</span></span><br><span class="line">        cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">        cudaEventRecord(mem_stop, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[0] = %d\n&quot;</span>,c[<span class="number">0</span>] );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[%d] = %d\n&quot;</span>,N<span class="number">-1</span>, c[N<span class="number">-1</span>] );</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* compute and print ellapsed time between start and stop */</span></span><br><span class="line">        <span class="type">float</span> elapsedTime, elapsedTotalTime;</span><br><span class="line">        cudaEventElapsedTime(&amp;elapsedTime, start, stop);</span><br><span class="line">        cudaEventElapsedTime(&amp;elapsedTotalTime, mem_start, mem_stop);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Time to load memory %3.1f ms\n&quot;</span>, elapsedTotalTime - elapsedTime);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Time to execute %3.1f ms\n&quot;</span>, elapsedTime);</span><br><span class="line">        cudaEventDestroy(start);</span><br><span class="line">        cudaEventDestroy(stop);</span><br><span class="line">        cudaEventDestroy(mem_start);</span><br><span class="line">        cudaEventDestroy(mem_stop);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* clean up */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/*free(a);</span></span><br><span class="line"><span class="comment">        free(b);</span></span><br><span class="line"><span class="comment">        free(c);*/</span></span><br><span class="line">        cudaFree( d_a );</span><br><span class="line">        cudaFree( d_b );</span><br><span class="line">        cudaFree( d_c );</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125; <span class="comment">/* end main */</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ./addvec</span><br><span class="line">c[0] = 0</span><br><span class="line">c[41943039] = 83886078</span><br><span class="line">Time to load memory 234.5 ms</span><br><span class="line">Time to execute 35.0 ms</span><br></pre></td></tr></table></figure>

<h3 id="流计算向量加法"><a href="#流计算向量加法" class="headerlink" title="流计算向量加法"></a>流计算向量加法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N (2048*2048)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> THREADS_PER_BLOCK 512</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NB_STREAMS 4</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SEGMENT_SIZE (1024*128)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CREATE_CUDAEVENT cudaEvent_t start, stop; \</span></span><br><span class="line"><span class="meta">cudaEventCreate(&amp;start); \</span></span><br><span class="line"><span class="meta">cudaEventCreate(&amp;stop);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> START_CUDAEVENT cudaEventRecord(start, 0);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> STOP_AND_PRINT_CUDAEVENT(txt) cudaEventRecord(stop, 0);\</span></span><br><span class="line"><span class="meta">cudaEventSynchronize(stop);\</span></span><br><span class="line"><span class="meta">&#123;float elapsedTime;\</span></span><br><span class="line"><span class="meta">cudaEventElapsedTime(&amp;elapsedTime, start, stop);\</span></span><br><span class="line"><span class="meta">printf(<span class="string">&quot;Time to %s %3.1f ms\n&quot;</span>, #txt, elapsedTime);&#125;</span></span><br><span class="line"></span><br><span class="line">__global__</span><br><span class="line"><span class="type">void</span> <span class="title function_">vector_add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">int</span> index = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">        c[index] = a[index] + b[index];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">stream_addition</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="comment">/*&lt; Add your code here, you can use the kernel without change it &gt;*/</span></span><br><span class="line"><span class="type">int</span> size = N * <span class="keyword">sizeof</span>( <span class="type">int</span> )/NB_STREAMS;</span><br><span class="line"></span><br><span class="line">cudaStream_t stream1 , stream2 , stream3, stream4;</span><br><span class="line">cudaStreamCreate (&amp; stream1 ) ;</span><br><span class="line">cudaStreamCreate (&amp; stream2 ) ;</span><br><span class="line">cudaStreamCreate (&amp; stream3 ) ;</span><br><span class="line">cudaStreamCreate (&amp; stream4 ) ;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> *d_a1, *d_b1, *d_c1;</span><br><span class="line"><span class="type">int</span> *d_a2, *d_b2, *d_c2;</span><br><span class="line"><span class="type">int</span> *d_a3, *d_b3, *d_c3;</span><br><span class="line"><span class="type">int</span> *d_a4, *d_b4, *d_c4;</span><br><span class="line"></span><br><span class="line">cudaMalloc( &amp;d_a1, size );</span><br><span class="line">cudaMalloc( &amp;d_b1, size );</span><br><span class="line">cudaMalloc( &amp;d_c1, size );</span><br><span class="line"></span><br><span class="line">cudaMalloc( &amp;d_a2, size );</span><br><span class="line">cudaMalloc( &amp;d_b2, size );</span><br><span class="line">cudaMalloc( &amp;d_c2, size );</span><br><span class="line"></span><br><span class="line">cudaMalloc( &amp;d_a3, size );</span><br><span class="line">cudaMalloc( &amp;d_b3, size );</span><br><span class="line">cudaMalloc( &amp;d_c3, size );</span><br><span class="line"></span><br><span class="line">cudaMalloc( &amp;d_a4, size );</span><br><span class="line">cudaMalloc( &amp;d_b4, size );</span><br><span class="line">cudaMalloc( &amp;d_c4, size );</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ( <span class="type">int</span> i =<span class="number">0</span>; i &lt; N ; i += SEGMENT_SIZE*NB_STREAMS) &#123;</span><br><span class="line">cudaMemcpyAsync( d_a1 , a +i , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ), cudaMemcpyHostToDevice, stream1 ) ;</span><br><span class="line">cudaMemcpyAsync( d_b1 , b +i , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ), cudaMemcpyHostToDevice, stream1 ) ;</span><br><span class="line"></span><br><span class="line">cudaMemcpyAsync( d_a2 , a +i + SEGMENT_SIZE , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ),cudaMemcpyHostToDevice,  stream2 ) ;</span><br><span class="line">cudaMemcpyAsync( d_b2 , b +i + SEGMENT_SIZE, SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) ,cudaMemcpyHostToDevice, stream2 ) ;</span><br><span class="line"></span><br><span class="line">cudaMemcpyAsync( d_a3 , a +i + <span class="number">2</span>*SEGMENT_SIZE, SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) ,cudaMemcpyHostToDevice, stream3 ) ;</span><br><span class="line">cudaMemcpyAsync( d_b3 , b +i + <span class="number">2</span>* SEGMENT_SIZE, SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) ,cudaMemcpyHostToDevice, stream3 ) ;</span><br><span class="line"></span><br><span class="line">cudaMemcpyAsync( d_a4 , a +i + <span class="number">3</span>*SEGMENT_SIZE , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) ,cudaMemcpyHostToDevice, stream4 ) ;</span><br><span class="line">cudaMemcpyAsync( d_b4 , b +i + <span class="number">3</span>*SEGMENT_SIZE , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) ,cudaMemcpyHostToDevice, stream4 ) ;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vector_add&lt;&lt;&lt;SEGMENT_SIZE/THREADS_PER_BLOCK, THREADS_PER_BLOCK,<span class="number">0</span>,stream1&gt;&gt;&gt;( d_a1, d_b1, d_c1);</span><br><span class="line">vector_add&lt;&lt;&lt;SEGMENT_SIZE/THREADS_PER_BLOCK, THREADS_PER_BLOCK,<span class="number">0</span>,stream2&gt;&gt;&gt;( d_a2, d_b2, d_c2);</span><br><span class="line">vector_add&lt;&lt;&lt;SEGMENT_SIZE/THREADS_PER_BLOCK, THREADS_PER_BLOCK,<span class="number">0</span>,stream3&gt;&gt;&gt;( d_a3, d_b3, d_c3);</span><br><span class="line">vector_add&lt;&lt;&lt;SEGMENT_SIZE/THREADS_PER_BLOCK, THREADS_PER_BLOCK,<span class="number">0</span>,stream4&gt;&gt;&gt;( d_a4, d_b4, d_c4);</span><br><span class="line"></span><br><span class="line">cudaMemcpyAsync( c + i, d_c1, SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) , cudaMemcpyDeviceToHost,stream1 );</span><br><span class="line">cudaMemcpyAsync( c +i+SEGMENT_SIZE , d_c2 , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) , cudaMemcpyDeviceToHost,stream2 );</span><br><span class="line">cudaMemcpyAsync( c+i+<span class="number">2</span>*SEGMENT_SIZE, d_c3 , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) ,cudaMemcpyDeviceToHost, stream3 );</span><br><span class="line">cudaMemcpyAsync( c+i+<span class="number">3</span>*SEGMENT_SIZE, d_c4 , SEGMENT_SIZE * <span class="keyword">sizeof</span> ( <span class="type">int</span> ) ,cudaMemcpyDeviceToHost, stream4 );</span><br><span class="line">&#125;</span><br><span class="line">cudaDeviceSynchronize();</span><br><span class="line">cudaFree( d_a1 );</span><br><span class="line">cudaFree( d_b1 );</span><br><span class="line">cudaFree( d_c1 );</span><br><span class="line"></span><br><span class="line">cudaFree( d_a2 );</span><br><span class="line">cudaFree( d_b2 );</span><br><span class="line">cudaFree( d_c2 );</span><br><span class="line"></span><br><span class="line">cudaFree( d_a3 );</span><br><span class="line">cudaFree( d_b3 );</span><br><span class="line">cudaFree( d_c3 );</span><br><span class="line"></span><br><span class="line">cudaFree( d_a4 );</span><br><span class="line">cudaFree( d_b4 );</span><br><span class="line">cudaFree( d_c4 );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">addition</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span></span><br><span class="line">&#123;</span><br><span class="line">        CREATE_CUDAEVENT</span><br><span class="line">        <span class="type">int</span> size = N * <span class="keyword">sizeof</span>( <span class="type">int</span> );</span><br><span class="line">        <span class="type">int</span> *d_a, *d_b, *d_c;</span><br><span class="line"></span><br><span class="line">        cudaMalloc( (<span class="type">void</span> **) &amp;d_a, size );</span><br><span class="line">        cudaMalloc( (<span class="type">void</span> **) &amp;d_b, size );</span><br><span class="line">        cudaMalloc( (<span class="type">void</span> **) &amp;d_c, size );</span><br><span class="line"></span><br><span class="line">        START_CUDAEVENT</span><br><span class="line">        <span class="title function_">cudaMemcpy</span><span class="params">( d_a, a, size, cudaMemcpyHostToDevice )</span>;</span><br><span class="line">        cudaMemcpy( d_b, b, size, cudaMemcpyHostToDevice );</span><br><span class="line">        STOP_AND_PRINT_CUDAEVENT(<span class="built_in">memcpy</span> h2d)</span><br><span class="line"></span><br><span class="line">        START_CUDAEVENT</span><br><span class="line">        vector_add&lt;&lt;&lt; (N + (THREADS_PER_BLOCK<span class="number">-1</span>)) / THREADS_PER_BLOCK, THREADS_PER_BLOCK &gt;&gt;&gt;( d_a, d_b, d_c );</span><br><span class="line">        STOP_AND_PRINT_CUDAEVENT(computation)</span><br><span class="line"></span><br><span class="line">        START_CUDAEVENT</span><br><span class="line">        <span class="title function_">cudaMemcpy</span><span class="params">( c, d_c, size, cudaMemcpyDeviceToHost )</span>;</span><br><span class="line">        STOP_AND_PRINT_CUDAEVENT(<span class="built_in">memcpy</span> d2h)</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* clean up */</span></span><br><span class="line">        cudaFree( d_a );</span><br><span class="line">        cudaFree( d_b );</span><br><span class="line">        cudaFree( d_c );</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">int</span> *a, *b, *c;</span><br><span class="line">        <span class="type">int</span> size = N * <span class="keyword">sizeof</span>( <span class="type">int</span> );</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Pinned memory */</span></span><br><span class="line">        cudaHostAlloc((<span class="type">void</span> **) &amp;a, size, cudaHostAllocDefault);</span><br><span class="line">        cudaHostAlloc((<span class="type">void</span> **) &amp;b, size, cudaHostAllocDefault);</span><br><span class="line">        cudaHostAlloc((<span class="type">void</span> **) &amp;c, size, cudaHostAllocDefault);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>( <span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++ )</span><br><span class="line">        &#123;</span><br><span class="line">                a[i] = b[i] = i;</span><br><span class="line">                c[i] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Addition with default stream\n&quot;</span>);</span><br><span class="line">        addition(a, b, c);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[0] = %d\n&quot;</span>,c[<span class="number">0</span>] );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[%d] = %d\n&quot;</span>,N<span class="number">-1</span>, c[N<span class="number">-1</span>] );</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>( <span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++ )</span><br><span class="line">        &#123;        c[i] = <span class="number">0</span>;         &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*&lt; Add a call to your function with streams &gt;*/</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Addition with streams\n&quot;</span>);</span><br><span class="line">        stream_addition(a, b, c);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[0] = %d\n&quot;</span>,c[<span class="number">0</span>] );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[%d] = %d\n&quot;</span>, N<span class="number">-1</span>, c[N<span class="number">-1</span>] );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[%d] = %d\n&quot;</span>, N/<span class="number">4</span><span class="number">-1</span>, c[N/<span class="number">4</span><span class="number">-1</span>] );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;c[%d] = %d\n&quot;</span>, <span class="number">6</span>, c[<span class="number">6</span>] );</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* clean up */</span></span><br><span class="line">        cudaFreeHost(a);</span><br><span class="line">        cudaFreeHost(b);</span><br><span class="line">        cudaFreeHost(c);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">./stream</span><br><span class="line">Addition with default stream</span><br><span class="line">Time to memcpy h2d 32.3 ms</span><br><span class="line">Time to computation 18.6 ms</span><br><span class="line">Time to memcpy d2h 17.1 ms</span><br><span class="line">c[0] = 0</span><br><span class="line">c[4194303] = 8388606</span><br><span class="line">Addition with streams</span><br><span class="line">c[0] = 0</span><br><span class="line">c[4194303] = 8388606</span><br><span class="line">c[1048575] = 2097150</span><br><span class="line">c[6] = 12</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

     
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>安然
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2023/02/19/GPU/2023-02-19-%E4%BB%A3%E7%A0%812/" title="">http://example.com/2023/02/19/GPU/2023-02-19-代码2/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/02/19/GPU/2023-02-19-%E4%BB%A3%E7%A0%811/" rel="prev" title="">
      <i class="fa fa-chevron-left"></i> 
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/02/20/QCM/2023-02-20-git/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#TD7"><span class="nav-number">1.</span> <span class="nav-text">TD7</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AF%94%E8%BE%83%E4%B8%8D%E5%90%8C%E5%86%85%E5%AD%98%E7%9A%84%E7%9F%A9%E9%98%B5%E5%8A%A0%E6%B3%95"><span class="nav-number">1.1.</span> <span class="nav-text">比较不同内存的矩阵加法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TD8-%E7%9B%B4%E6%96%B9%E5%9B%BE%E7%BB%9F%E8%AE%A1"><span class="nav-number">2.</span> <span class="nav-text">TD8 直方图统计</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TD9"><span class="nav-number">3.</span> <span class="nav-text">TD9</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pinned%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97%E5%90%91%E9%87%8F%E5%8A%A0%E6%B3%95"><span class="nav-number">3.1.</span> <span class="nav-text">Pinned内存计算向量加法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%81%E8%AE%A1%E7%AE%97%E5%90%91%E9%87%8F%E5%8A%A0%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">流计算向量加法</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="安然"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">安然</p>
  <div class="site-description" itemprop="description">随手写点什么</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/JeanneSHen" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;JeanneSHen" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:shenanran1114@gmail.com" title="E-Mail → mailto:shenanran1114@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; Wed Sep 21 2022 02:00:00 GMT+0200 (中欧夏令时间) – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">安然</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不算子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
